{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e374a944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3622dec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import os\n",
    "import time\n",
    "from xml.dom.minidom import parse\n",
    "import xml.dom.minidom\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d65da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 转换 sumo 的 string 格式的 edge id，node id 为 integer 的格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "330fcdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path is: /Users/xuzizhuo/Desktop/Main Folder/My_works/Traffic_Simulation_Work/Traffic_Simulation_Data_Generation_for_Baselines/test.net.xml\n",
      "Number of edges are:  29493\n"
     ]
    }
   ],
   "source": [
    "# Capture network information from \".xml\" and save into \".csv\"\n",
    "\n",
    "'''\n",
    "SUMO 的道路网络中包含了很多连接信息，这行代码从中提取以下需要的信息：\n",
    "1. edge ID，\n",
    "2. edge ID 对应的特征（路长，限速，lanes number），\n",
    "3. 连接 edge ID 的两个 node IDs，\n",
    "'''\n",
    "\n",
    "def network_data_exploration(filename):\n",
    "    # Define path\n",
    "    path = os.path.abspath('./../../../Traffic_Simulation_Data_Generation_for_Baselines/') \n",
    "    # Define data path\n",
    "    data_path = os.path.join(path,filename) \n",
    "    print('Data path is:', data_path) \n",
    "    \n",
    "    # Open \".xml\" and find data\n",
    "    DOMTree = xml.dom.minidom.parse(data_path) \n",
    "    data = DOMTree.documentElement \n",
    "    \n",
    "    # Get element list\n",
    "    nodeList = data.getElementsByTagName(\"edge\")\n",
    "    print(\"Number of edges are: \", len(nodeList))\n",
    "    \n",
    "    # Define and initilzie explored data\n",
    "    all_rows = []\n",
    "    \n",
    "    for node in nodeList: \n",
    "        # Get features of each edge\n",
    "        edge_ID = node.getAttribute(\"id\")\n",
    "        node_start = node.getAttribute(\"from\")\n",
    "        node_end = node.getAttribute(\"to\")\n",
    "        priority = node.getAttribute(\"priority\")\n",
    "        # Get element list of edge\n",
    "        subNodeList = node.getElementsByTagName(\"lane\")\n",
    "        \n",
    "        # Initialize features\n",
    "        speed = 0\n",
    "        length = 0\n",
    "        for subNode in subNodeList:\n",
    "            # Get features of each lane\n",
    "            speed += float(subNode.getAttribute(\"speed\"))\n",
    "        \n",
    "            length += float(subNode.getAttribute(\"length\"))\n",
    "        speed_avg = speed / len(subNodeList)\n",
    "        length_avg = length / len(subNodeList)\n",
    "        lane_num = len(subNodeList)\n",
    "            \n",
    "        newRow = {\"edge_id\": edge_ID, \"node_start\": node_start, \"node_end\": node_end, \"lane_num\":lane_num, \"speed\": speed_avg, \"length\": length_avg, \"priority\": priority}\n",
    "        all_rows.append(newRow)\n",
    "              \n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    return df\n",
    " \n",
    "    \n",
    "# Call function to export network information data\n",
    "df = network_data_exploration(\"test.net.xml\")\n",
    "df.head()\n",
    "df.to_csv('Manhattan_network_raw.csv', index=False)\n",
    "\n",
    "# Potential mistakes:\n",
    "# Edges allow different types of vehicles but do not considered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00a3d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "构建 SUMO 路网信息映射成 int 格式的，Simulation Algorithm 可读的词典：\n",
    "1. 把 string 结构的 node ID 转成 int 结构的：node_to_int，\n",
    "2. 把 string 结构的 edge ID 转成 int 结构的：edge_to_int，\n",
    "3. 把 int 结构的 edge ID 转成 string 结构的：int_to_edge，\n",
    "4. 储存 int 结构的 node ID 和 edge ID 到 Manhattan_network_mapped.csv 中。\n",
    "'''\n",
    "\n",
    "\n",
    "# Map edge and node ID from 0 to their length\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv('Manhattan_network_raw.csv')\n",
    "\n",
    "# Convert unique string ids of \"node_start\" and \"node_end\" to unique integers.\n",
    "# Get a list of unique nodes\n",
    "unique_nodes = pd.concat([df['node_start'], df['node_end']]).unique()\n",
    "# Create a mapping of node string id to integer\n",
    "node_to_int = {node: idx for idx, node in enumerate(unique_nodes)}\n",
    "# Replace the string ids in the dataframe\n",
    "df['node_start'] = df['node_start'].map(node_to_int)\n",
    "df['node_end'] = df['node_end'].map(node_to_int)\n",
    "\n",
    "# Convert \"edge_id\" to unique integers.\n",
    "# Create a mapping of edge string id to integer\n",
    "edge_to_int = {edge: idx for idx, edge in enumerate(df['edge_id'].unique())}\n",
    "# Replace the string ids in the dataframe\n",
    "df['edge_id'] = df['edge_id'].map(edge_to_int)\n",
    "\n",
    "\n",
    "# 反转 edge_to_int 映射\n",
    "int_to_edge = {v: k for k, v in edge_to_int.items()}\n",
    "\n",
    "\n",
    "# Save mapped dataframe\n",
    "df.to_csv('Manhattan_network_mapped.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10c04eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25897"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_to_int['727135244#3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83273863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'727135244#3'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_edge[25897]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2f0192b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path is: /Users/xuzizhuo/Desktop/Main Folder/My_works/Traffic_Simulation_Work/Traffic_Simulation_Data_Generation_for_Baselines/test.net.xml\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import networkx as nx\n",
    "import os\n",
    "\n",
    "def parse_sumo_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    edges = {}\n",
    "    connections = []\n",
    "\n",
    "    for edge in root.findall('.//edge'):\n",
    "        edge_id = edge.get('id')\n",
    "        edges[edge_id] = {\n",
    "            'from': edge.get('from'),\n",
    "            'to': edge.get('to')\n",
    "        }\n",
    "\n",
    "    for connection in root.findall('.//connection'):\n",
    "        from_edge = connection.get('from')\n",
    "        to_edge = connection.get('to')\n",
    "        direction = connection.get('dir')  # 提取连接的方向\n",
    "        connections.append((from_edge, to_edge, direction))\n",
    "\n",
    "    return edges, connections\n",
    "\n",
    "path = os.path.abspath('./../../../Traffic_Simulation_Data_Generation_for_Baselines/') \n",
    "xml_file = os.path.join(path,'test.net.xml') \n",
    "print('Data path is:', xml_file) \n",
    "\n",
    "edges, connections = parse_sumo_xml(xml_file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c256806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_connections_to_csv(connections, edge_to_int, filename):\n",
    "    with open(filename, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['from_edge', 'to_edge', 'direction'])  # 写入标题行\n",
    "        \n",
    "        for from_edge, to_edge, direction in connections:\n",
    "            from_edge_int = edge_to_int[from_edge]\n",
    "            to_edge_int = edge_to_int[to_edge]\n",
    "            writer.writerow([from_edge_int, to_edge_int, direction])\n",
    "\n",
    "# 假设 xml_file 是你的XML文件路径，node_mapping 是已经创建的映射\n",
    "edges, connections = parse_sumo_xml(xml_file)\n",
    "\n",
    "# 现在我们假设 node_mapping 已经存在\n",
    "# 例如：node_mapping = {'993510828#1': 1, '32973204#0': 2}\n",
    "\n",
    "# 调用 save_connections_to_csv 来保存转换后的信息\n",
    "save_connections_to_csv(connections, edge_to_int, 'connections_to_directions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aec85bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 构建映射后的 int edge id 和其 static features 的文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f002ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "生成 int 结构 edge ID -> lane_num，speed_limit，average_length 的词典 edge_id_to_features，\n",
    "储存词典 edge_id_to_features 到 csv 文件，方便 C++ 读取。\n",
    "'''\n",
    "\n",
    "# 读取预处理后的数据\n",
    "df = pd.read_csv('Manhattan_network_mapped.csv')\n",
    "\n",
    "# 初始化一个空字典来存储整数 edge_id 映射到其特征的信息\n",
    "edge_id_to_features = {}\n",
    "\n",
    "# 遍历 DataFrame 的每一行\n",
    "for index, row in df.iterrows():\n",
    "    # 为当前 edge_id 存储 lane_num, speed, 和 length 的信息\n",
    "    edge_id_to_features[row['edge_id']] = {\n",
    "        \"lane_num\": row['lane_num'],\n",
    "        \"speed\": row['speed'],\n",
    "        \"length\": row['length'],\n",
    "        \"edge_str\": int_to_edge[row['edge_id']]\n",
    "    }\n",
    "\n",
    "# 将字典保存为 CSV 文件\n",
    "with open('edge_id_to_features.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"edge_id\", \"lane_num\", \"speed\", \"length\", \"edge_str\"])  # 写入标题\n",
    "    for edge_id, features in edge_id_to_features.items():\n",
    "        writer.writerow([edge_id, features['lane_num'], features['speed'], features['length'], features['edge_str']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0c597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4e39829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge to Nodes Mapping: (7480410399, 42437990)\n",
      "Nodes to Edge Mapping: -1004369132#0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "构建词典 nodes_to_edge_raw 和 edge_to_nodes_raw：\n",
    "1. edge_to_nodes_raw：从 string 结构的 edge ID 映射成 string 结构的 node IDs\n",
    "2. nodes_to_edge_raw：从 string 结构的 node IDs 映射成 string 结构的 edge ID\n",
    "'''\n",
    "\n",
    "# Map edge to node pairs & node pairs to edges\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('Manhattan_network_raw.csv')\n",
    "\n",
    "# 初始化两个字典\n",
    "edge_to_nodes_raw = {}  # edge_id 映射到 node_start 和 node_end\n",
    "nodes_to_edge_raw = {}  # node_start 和 node_end 映射到 edge_id\n",
    "\n",
    "# 遍历 DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    edge_id = row['edge_id']\n",
    "    node_start = row['node_start']\n",
    "    node_end = row['node_end']\n",
    "\n",
    "    # 建立 edge_id 到 node_start 和 node_end 的映射\n",
    "    edge_to_nodes_raw[edge_id] = (node_start, node_end)\n",
    "\n",
    "    # 建立 node_start 和 node_end 到 edge_id 的映射\n",
    "    nodes_to_edge_raw[(node_start, node_end)] = edge_id\n",
    "\n",
    "# 测试输出\n",
    "print(\"Edge to Nodes Mapping:\", edge_to_nodes_raw[\"-1004369132#0\"])\n",
    "print(\"Nodes to Edge Mapping:\", nodes_to_edge_raw[(7480410399, 42437990)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90d0a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "构建词典 nodes_to_edge_mapped 和 edge_to_nodes_mapped：\n",
    "1. edge_to_nodes_mapped：从 int 结构的 edge ID 映射成 int 结构的 node IDs\n",
    "2. nodes_to_edge_mapped：从 int 结构的 node IDs 映射成 int 结构的 edge ID\n",
    "'''\n",
    "\n",
    "\n",
    "# Map edge to node pairs & node pairs to edges\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('Manhattan_network_mapped.csv')\n",
    "\n",
    "# 初始化两个字典\n",
    "edge_to_nodes_mapped = {}  # edge_id 映射到 node_start 和 node_end\n",
    "nodes_to_edge_mapped = {}  # node_start 和 node_end 映射到 edge_id\n",
    "\n",
    "# 遍历 DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    edge_id = row['edge_id']\n",
    "    node_start = row['node_start']\n",
    "    node_end = row['node_end']\n",
    "\n",
    "    # 建立 edge_id 到 node_start 和 node_end 的映射\n",
    "    edge_to_nodes_mapped[edge_id] = (node_start, node_end)\n",
    "\n",
    "    # 建立 node_start 和 node_end 到 edge_id 的映射\n",
    "    nodes_to_edge_mapped[(node_start, node_end)] = edge_id\n",
    "\n",
    "# 测试输出\n",
    "# print(\"Edge to Nodes Mapping:\", edge_to_nodes_mapped[0])\n",
    "# print(\"Nodes to Edge Mapping:\", nodes_to_edge_mapped[(0, 9115)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42c91880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'46201646'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_to_edge_mapped[(12573, 9504)]\n",
    "int_to_edge[16133]\n",
    "\n",
    "# edge id=\"46201646\" from=\"370913784\" to=\"370914027\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74e1585d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'961976870'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_to_edge_mapped[(9504, 9520)]\n",
    "int_to_edge[28341]\n",
    "\n",
    "# edge id=\"960097006\" from=\"370914027\" to=\"589099584\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fadae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52bb75b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of unqiue nodes:  20853\n",
      "Length of unique edges:  29493\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "把 SUMO 的路网结构存成 Simulation Algorithm 可读的\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Paths for the input and output files\n",
    "csv_file_path = 'Manhattan_network_mapped.csv'\n",
    "txt_file_path1 = 'Manhattan_network_BJ.txt'\n",
    "txt_file_path2 = 'Manhattan_network_min_Travel_Time.txt'\n",
    "\n",
    "# Loading the CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Calculating unique nodes and edges\n",
    "unique_nodes = pd.concat([df['node_start'], df['node_end']]).unique()\n",
    "unique_edges = df['edge_id'].unique()\n",
    "\n",
    "# The two integer values to be added at the beginning of each .txt file\n",
    "int_val_1 = len(unique_nodes)\n",
    "print(\"Length of unqiue nodes: \", len(unique_nodes))\n",
    "int_val_2 = len(unique_edges)\n",
    "print(\"Length of unique edges: \", len(unique_edges))\n",
    "\n",
    "# Generating the first .txt file\n",
    "with open(txt_file_path1, 'w') as txt_file1:\n",
    "    # Writing the two integers to the TXT file\n",
    "    txt_file1.write(f\"{int(int_val_1)} {int(int_val_2)}\\n\")\n",
    "    \n",
    "    # Iterating over rows in the DataFrame to format and write each row according to specifications\n",
    "    for index, row in df.iterrows():\n",
    "        txt_file1.write(f\"{int(row['node_start'])} {int(row['node_end'])} {int(row['edge_id'])} {round(row['length'],2)}\\n\")\n",
    "\n",
    "# Generating the second .txt file\n",
    "with open(txt_file_path2, 'w') as txt_file2:\n",
    "    # Writing the two integers to the TXT file\n",
    "    txt_file2.write(f\"{int(int_val_1)} {int(int_val_2)}\\n\")\n",
    "    \n",
    "    # Iterating over rows in the DataFrame to format and write each row according to specifications\n",
    "    for index, row in df.iterrows():\n",
    "        travel_time = round(row['length'] / row['speed'],2)  # Calculating travel time as length_avg / speed_avg\n",
    "        txt_file2.write(f\"{int(row['node_start'])} {int(row['node_end'])} {travel_time}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc91034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6b64bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 转换 route 数据为 sumo 可读的格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ba79b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of routes are:  192484\n",
      "Number of route is: 192484\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "SUMO 在模拟结束后可以生成轨迹数据，\n",
    "以下代码从轨迹数据中提取轨迹数据的相应信息\n",
    "'''\n",
    "\n",
    "# Capture trajectory data from \".xml\" file to \".csv\" file\n",
    "\n",
    "def trajectory_information_capture(filename):\n",
    "    #获取xml文件地址\n",
    "    path = os.path.abspath('./../../../Traffic_Simulation_Data_Generation_for_Baselines/0/') \n",
    "    #获取xml文件地址\n",
    "    data_path = os.path.join(path,filename) \n",
    "    \n",
    "    # 打开xml文档\n",
    "    DOMTree = xml.dom.minidom.parse(data_path) \n",
    "    # 根据xml文档，得到文档元素的对象\n",
    "    data = DOMTree.documentElement \n",
    "    \n",
    "    # 获取节点列表\n",
    "    nodeList = data.getElementsByTagName(\"vehicle\")\n",
    "    # 定义route数量\n",
    "    nodeLen = len(nodeList)\n",
    "    print(\"Length of routes are: \", nodeLen)\n",
    "    \n",
    "    all_rows = []\n",
    "    routeID_set = set()\n",
    "    for node in nodeList: \n",
    "        # 获取当前节点属性值\n",
    "        route_ID = node.getAttribute(\"id\")\n",
    "        depart_time = node.getAttribute(\"depart\")\n",
    "        # arrival_time = node.getAttribute(\"arrival\")\n",
    "        \n",
    "        subNodeList = node.getElementsByTagName(\"route\")\n",
    "        \n",
    "        for subNode in subNodeList:\n",
    "            if len(subNodeList) != 1:\n",
    "                print(\"Error.\")\n",
    "            \n",
    "            # 获取当前节点属性值\n",
    "            route = subNode.getAttribute(\"edges\")\n",
    "            # exit_times = subNode.getAttribute(\"exitTimes\")\n",
    "            # 拆分字符串\n",
    "            ids = route.split()\n",
    "            # 提取第一个和最后一个ID\n",
    "            start_node = ids[0]\n",
    "            end_node = ids[-1]\n",
    "        \n",
    "        # newRow = {\"route_id\": route_ID, \"depart_time\": depart_time, \"arrival_time\": arrival_time, \n",
    "        #           \"start_edge\": start_node, \"end_edge\": end_node, \"route_by_edge\": route, \"exit_times\": exit_times}\n",
    "        \n",
    "        newRow = {\"route_id\": route_ID, \"depart_time\": depart_time,\n",
    "                  \"start_edge\": start_node, \"end_edge\": end_node, \"route_by_edge\": route}\n",
    "        \n",
    "        routeID_set.add(route_ID)\n",
    "        all_rows.append(newRow)\n",
    "\n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    print(f\"Number of route is: {len(routeID_set)}\")\n",
    "    return df\n",
    "\n",
    "# df_trajectory = trajectory_information_capture(\"outputfile.xml\")\n",
    "df_trajectory = trajectory_information_capture(\"merged_trips.trips.xml\")\n",
    "\n",
    "df_trajectory.to_csv('Manhattan_trajectory_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a8f960b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>depart_time</th>\n",
       "      <th>start_edge</th>\n",
       "      <th>end_edge</th>\n",
       "      <th>route_by_edge</th>\n",
       "      <th>route_by_mappped_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25167444</td>\n",
       "      <td>-195743156#0</td>\n",
       "      <td>25167444 -194923762#1 -194923762#0 -194923763#...</td>\n",
       "      <td>9122.0 716.0 715.0 720.0 719.0 718.0 717.0 127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204085726#0</td>\n",
       "      <td>5671345#12</td>\n",
       "      <td>204085726#0 204085726#1 204085726#2 1016808887...</td>\n",
       "      <td>8517.0 8518.0 8519.0 4960.0 4961.0 10583.0 105...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346951422#0</td>\n",
       "      <td>945375290#3</td>\n",
       "      <td>346951422#0 346951422#1 154716102#0 154716102#...</td>\n",
       "      <td>2763.0 1581.0 1582.0 7320.0 1627.0 2627.0 2626...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>953819149#0</td>\n",
       "      <td>5671661#2</td>\n",
       "      <td>953819149#0 953819149#1 953819152 953819150 11...</td>\n",
       "      <td>19852.0 19853.0 19851.0 17508.0 4782.0 365.0 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-46334665#3</td>\n",
       "      <td>46577943</td>\n",
       "      <td>-46334665#3 -46334665#2 -46334665#1 -46334665#...</td>\n",
       "      <td>2551.0 2550.0 2549.0 2548.0 271.0 270.0 269.0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   route_id  depart_time   start_edge      end_edge  \\\n",
       "0         1          0.0     25167444  -195743156#0   \n",
       "1         2          0.0  204085726#0    5671345#12   \n",
       "2         3          0.0  346951422#0   945375290#3   \n",
       "3         4          0.0  953819149#0     5671661#2   \n",
       "4         5          0.0  -46334665#3      46577943   \n",
       "\n",
       "                                       route_by_edge  \\\n",
       "0  25167444 -194923762#1 -194923762#0 -194923763#...   \n",
       "1  204085726#0 204085726#1 204085726#2 1016808887...   \n",
       "2  346951422#0 346951422#1 154716102#0 154716102#...   \n",
       "3  953819149#0 953819149#1 953819152 953819150 11...   \n",
       "4  -46334665#3 -46334665#2 -46334665#1 -46334665#...   \n",
       "\n",
       "                               route_by_mappped_node  \n",
       "0  9122.0 716.0 715.0 720.0 719.0 718.0 717.0 127...  \n",
       "1  8517.0 8518.0 8519.0 4960.0 4961.0 10583.0 105...  \n",
       "2  2763.0 1581.0 1582.0 7320.0 1627.0 2627.0 2626...  \n",
       "3  19852.0 19853.0 19851.0 17508.0 4782.0 365.0 3...  \n",
       "4  2551.0 2550.0 2549.0 2548.0 271.0 270.0 269.0 ...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert raw edge IDs constructed route into mapped node IDs\n",
    "# e.g. raw_edge_1 raw_edge_2 ... -> mapped_node_1 mapped_node_2 mapped_node_3\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('Manhattan_trajectory_raw.csv')\n",
    "\n",
    "# 初始化新列\n",
    "df['route_by_mappped_node'] = None\n",
    "\n",
    "# 遍历 DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # 分割 route_by_edge 字符串并应用映射\n",
    "    node_pairs = [edge_to_nodes_mapped[edge_to_int[edge_id]] for edge_id in row['route_by_edge'].split(' ') if edge_id in edge_to_int]\n",
    "\n",
    "    # 处理节点序列，确保节点不重复\n",
    "    node_sequence = []\n",
    "    for pair in node_pairs:\n",
    "        # 确保节点转换为字符串\n",
    "        node_start = str(pair[0])\n",
    "        node_end = str(pair[1])\n",
    "\n",
    "        if not node_sequence or node_sequence[-1] != node_start:\n",
    "            node_sequence.append(node_start)\n",
    "        node_sequence.append(node_end)\n",
    "\n",
    "    # 更新新列\n",
    "    df.at[index, 'route_by_mappped_node'] = ' '.join(node_sequence)\n",
    "\n",
    "# 保存到新的 CSV 文件\n",
    "df.to_csv('Manhattan_trajectory_mapped_node.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e842c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "611c3944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5s/rs3sd7x95x9cf24kymvs99d40000gn/T/ipykernel_64140/1164579865.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Travel_Time'] = pd.to_numeric(df['Travel_Time'], errors='coerce') + pd.to_numeric(df['Delay_Time'], errors='coerce') + pd.to_numeric(df['LowSpee_Time'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 使用示例\n",
    "path = os.path.abspath('./../../../Traffic_Simulation_Data_Generation_for_Baselines/0/') \n",
    "# Define data path\n",
    "input_csv_path = os.path.join(path, 'TraCI_output_adjusted.csv')\n",
    "\n",
    "# Read the CSV data\n",
    "df_ETA = pd.read_csv(input_csv_path)\n",
    "\n",
    "# 选择相关列\n",
    "df = df_ETA[['Vehicle_ID', 'E_Length', 'Edge_ID', 'Speed_Net', 'Time', 'Travel_Time', 'Delay_Time', 'LowSpee_Time']]\n",
    "\n",
    "# Add Wait_Sum to Travel_Time\n",
    "df['Travel_Time'] = pd.to_numeric(df['Travel_Time'], errors='coerce') + pd.to_numeric(df['Delay_Time'], errors='coerce') + pd.to_numeric(df['LowSpee_Time'], errors='coerce')\n",
    "\n",
    "df.loc[df['E_Length'] / df['Speed_Net'] < 1, 'Travel_Time'] = 0\n",
    "\n",
    "# 对于不同 Edge_ID 的 Travel_Time 求平均，构建词典，key 是 Edge_ID，value 是平均 Travel_Time\n",
    "average_travel_time_dict = df.groupby('Edge_ID')['Travel_Time'].mean().to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7983b5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36b64b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证：\n",
    "# trips 文件中包含的 route 数据和 TraCI 转换出来的 route 数据的正确性是否对应\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ece614cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192484\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('Manhattan_trajectory_raw.csv')\n",
    "\n",
    "# 初始化一个空字典\n",
    "route_dict = {}\n",
    "\n",
    "# 遍历每一行，构建词典\n",
    "for index, row in df.iterrows():\n",
    "    route_id = row['route_id']\n",
    "    edge_ids = row['route_by_edge'].split(' ')  # 将 edge ids 拆分成列表\n",
    "    route_dict[route_id] = edge_ids\n",
    "\n",
    "# 输出词典\n",
    "print(len(route_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eb22c373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5s/rs3sd7x95x9cf24kymvs99d40000gn/T/ipykernel_64140/4210898589.py:20: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[['Delay_Time', 'LowSpee_Time', 'Wait_Time']] = df[['Delay_Time', 'LowSpee_Time', 'Wait_Time']].applymap(lambda x: 0 if x == 0 else 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已处理 5000000 行数据\n",
      "已处理 10000000 行数据\n",
      "已处理 15000000 行数据\n",
      "已处理 20000000 行数据\n",
      "已处理 25000000 行数据\n",
      "已处理 30000000 行数据\n",
      "已处理 35000000 行数据\n",
      "已处理 40000000 行数据\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 获取CSV文件地址\n",
    "path = os.path.abspath('./../../../Traffic_Simulation_Data_Generation_for_Baselines/0/') \n",
    "data_path = os.path.join(path, 'TraCI_output_adjusted.csv')\n",
    "\n",
    "# 载入CSV文件\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# 将 'Travel_Time' 计算为三列之和\n",
    "df['Travel_Time'] = pd.to_numeric(df['Travel_Time'], errors='coerce') + \\\n",
    "                    pd.to_numeric(df['Delay_Time'], errors='coerce') + \\\n",
    "                    pd.to_numeric(df['LowSpee_Time'], errors='coerce')\n",
    "\n",
    "# 将 E_Length / Speed_Net 小于 1 的行的 Travel_Time 设为 0\n",
    "df.loc[df['E_Length'] / df['Speed_Net'] < 1, 'Travel_Time'] = 0\n",
    "\n",
    "# 将 'Delay_Time', 'LowSpee_Time', 'Wait_Time' 转换为 0 和 1 的形式\n",
    "df[['Delay_Time', 'LowSpee_Time', 'Wait_Time']] = df[['Delay_Time', 'LowSpee_Time', 'Wait_Time']].applymap(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "# 初始化计数器\n",
    "row_count = 0\n",
    "    \n",
    "# 构建 vehicle_edge_time_dict 词典\n",
    "vehicle_edge_time_dict = {}\n",
    "for index, row in df.iterrows():\n",
    "    vehicle_id = row['Vehicle_ID']\n",
    "    edge_id = row['Edge_ID']\n",
    "    \n",
    "    # 构建内层词典\n",
    "    time_data = {\n",
    "        'Delay_Time': row['Delay_Time'],\n",
    "        'LowSpee_Time': row['LowSpee_Time'],\n",
    "        'Wait_Time': row['Wait_Time'],\n",
    "        'Travel_Time': row['Travel_Time']\n",
    "    }\n",
    "    \n",
    "    # 如果该 vehicle_id 已存在于字典中\n",
    "    if vehicle_id in vehicle_edge_time_dict:\n",
    "        # 如果 edge_id 还没有被记录过，添加它\n",
    "        if edge_id not in vehicle_edge_time_dict[vehicle_id]:\n",
    "            vehicle_edge_time_dict[vehicle_id][edge_id] = time_data\n",
    "        else:\n",
    "            # 如果 edge_id 已存在，可以选择更新数据或者跳过\n",
    "            print(f\"Edge {edge_id} 已存在于 vehicle {vehicle_id} 中\")\n",
    "    else:\n",
    "        # 如果该 vehicle_id 不存在，初始化一个新的词典\n",
    "        vehicle_edge_time_dict[vehicle_id] = {edge_id: time_data}\n",
    "\n",
    "\n",
    "    # 更新计数器\n",
    "    row_count += 1\n",
    "\n",
    "    # 每处理100万行输出进度\n",
    "    if row_count % 5000000 == 0:\n",
    "        print(f\"已处理 {row_count} 行数据\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c148794c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "验证1:词典长度一致\n",
      "验证2.1 : 检查 route_dict 中的 edge ids 是否包含重复:\n",
      "验证3: 检查 route_dict 是否包含 vehicle_edge_time_dict 的 edge ids:\n"
     ]
    }
   ],
   "source": [
    "# 1. 验证两个词典的长度是否相同\n",
    "if len(route_dict) != len(vehicle_edge_time_dict):\n",
    "    print(f\"Error: 词典长度不一致 - route_dict 长度: {len(route_dict)}, vehicle_edge_time_dict 长度: {len(vehicle_edge_time_dict)}\")\n",
    "else:\n",
    "    print(\"验证1:词典长度一致\")\n",
    "\n",
    "# 2. 验证每个 route_id 的 edge ids 是否包含重复\n",
    "def check_duplicates(route_dict):\n",
    "    for route_id, edge_ids in route_dict.items():\n",
    "        if len(edge_ids) != len(set(edge_ids)):\n",
    "            print(f\"Error: route_id {route_id} 中存在重复的 edge ids\")\n",
    "        # else:\n",
    "        #     print(f\"route_id {route_id} 中不存在重复的 edge ids\")\n",
    "\n",
    "# 检查 route_dict 是否有重复的 edge ids\n",
    "print(\"验证2.1 : 检查 route_dict 中的 edge ids 是否包含重复:\")\n",
    "check_duplicates(route_dict)\n",
    "\n",
    "'''\n",
    "# 检查 vehicle_edge_time_dict 中的 edge ids 是否包含重复\n",
    "print(\"检查 vehicle_edge_time_dict 中的 edge ids 是否包含重复:\")\n",
    "for route_id, edge_dict in vehicle_edge_time_dict.items():\n",
    "    edge_ids = list(edge_dict.keys())\n",
    "    if len(edge_ids) != len(set(edge_ids)):\n",
    "        print(f\"Error: route_id {route_id} 中存在重复的 edge ids\")\n",
    "    else:\n",
    "        print(f\"route_id {route_id} 中不存在重复的 edge ids\")\n",
    "'''\n",
    "\n",
    "# 3. 验证 route_dict 的 edge ids 是否包含 vehicle_edge_time_dict 中的 edge ids\n",
    "print(\"验证3: 检查 route_dict 是否包含 vehicle_edge_time_dict 的 edge ids:\")\n",
    "for route_id, edge_dict in vehicle_edge_time_dict.items():\n",
    "    if route_id in route_dict:\n",
    "        route_edges = set(route_dict[route_id])\n",
    "        vehicle_edges = set(edge_dict.keys())\n",
    "        \n",
    "        # 如果 route_dict 的 edge ids 不完全包含 vehicle_edge_time_dict 的 edge ids，打印错误\n",
    "        if not vehicle_edges.issubset(route_edges):\n",
    "            print(f\"Error: route_id {route_id} 的 edge ids 不完全包含在 route_dict 中\")\n",
    "        # else:\n",
    "        #     print(f\"route_id {route_id} 的 edge ids 完全包含在 route_dict 中\")\n",
    "    else:\n",
    "        print(f\"Error: route_id {route_id} 不存在于 route_dict 中\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7354e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0bb1352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 补全数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30f5596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历 route_id 并处理每个 route_id 下的 edge ids\n",
    "for route_id in route_dict:\n",
    "    \n",
    "    # 1. 获取 route_dict 中的 edge ids\n",
    "    route_edges = route_dict[route_id]  # 这个是完整的 edge ids 列表\n",
    "    \n",
    "    # 2. 检查 vehicle_edge_time_dict 中是否有这个 route_id\n",
    "    if route_id in vehicle_edge_time_dict:\n",
    "        # 获取 vehicle_edge_time_dict 中当前 route_id 下的 edge ids\n",
    "        vehicle_edges = list(vehicle_edge_time_dict[route_id].keys())\n",
    "    else:\n",
    "        # 如果 vehicle_edge_time_dict 中没有该 route_id，初始化一个空的嵌套字典\n",
    "        print(f\"Error: route_id {route_id} 不存在于 vehicle_edge_time_dict 中\")\n",
    "        vehicle_edge_time_dict[route_id] = {}\n",
    "        vehicle_edges = []\n",
    "\n",
    "    # 3. 找出缺失的 edge ids：在 route_dict 中但不在 vehicle_edge_time_dict 中的 edge ids\n",
    "    missing_edges = [edge_id for edge_id in route_edges if edge_id not in vehicle_edges]\n",
    "    \n",
    "    # 4. 对于缺失的 edge ids，补全 vehicle_edge_time_dict 中的值\n",
    "    for edge_id in missing_edges:\n",
    "        # 初始化为0的值，包含所有字段\n",
    "        vehicle_edge_time_dict[route_id][edge_id] = {\n",
    "            'Delay_Time': 0,\n",
    "            'LowSpee_Time': 0,\n",
    "            'Wait_Time': 0,\n",
    "            'Travel_Time': 0\n",
    "        }\n",
    "\n",
    "    # 5. 保持顺序（可选）：将 vehicle_edge_time_dict 的 edge ids 按照 route_dict 的顺序排列\n",
    "    # 我们先获取完整的 edge ids 顺序列表\n",
    "    ordered_edges = {edge_id: vehicle_edge_time_dict[route_id][edge_id] for edge_id in route_edges}\n",
    "    \n",
    "    # 将有序的 edge ids 重新赋值回 vehicle_edge_time_dict 中\n",
    "    vehicle_edge_time_dict[route_id] = ordered_edges\n",
    "\n",
    "# 最终检查结果，确认每个 route_id 的 edge ids 是否已经被补全\n",
    "for route_id in vehicle_edge_time_dict:\n",
    "    if not set(vehicle_edge_time_dict[route_id].keys()) == set(route_dict[route_id]):\n",
    "        print(f\"Error: route_id {route_id} 未能成功补全\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81f3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f27b11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline：\n",
    "# routeETA 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b849a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ea9b116f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Mean Absolute Error): 28.172839039487258\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 设定参数 N\n",
    "N = 50\n",
    "\n",
    "# 初始化两个列表，用于存储 truth 和 预测的 travel time 总和\n",
    "truth_values = []\n",
    "predicted_values = []\n",
    "\n",
    "# 遍历 vehicle_edge_time_dict 中的每个 route_id\n",
    "for route_id, edge_time_dict in vehicle_edge_time_dict.items():\n",
    "    \n",
    "    # 获取该 route_id 下的所有 edge ids 列表\n",
    "    route_edges = list(edge_time_dict.keys())\n",
    "    \n",
    "    # 取前 N 个 edge ids，如果总长度小于 N，则取所有 edge\n",
    "    selected_edges = route_edges[:N]\n",
    "    \n",
    "    # 计算 truth: 取前 N 个 edge 的 Travel_Time 之和\n",
    "    truth_travel_time = sum(edge_time_dict[edge_id]['Travel_Time'] for edge_id in selected_edges)\n",
    "    \n",
    "    # 计算预测值：根据前 N 个 edge 从 average_travel_time_dict 中取 travel time 的和\n",
    "    predicted_travel_time = sum(average_travel_time_dict.get(edge_id, 0) for edge_id in selected_edges)\n",
    "    \n",
    "    # 将 truth 和预测值分别添加到列表中\n",
    "    truth_values.append(truth_travel_time)\n",
    "    predicted_values.append(predicted_travel_time)\n",
    "\n",
    "# 计算 MAE (Mean Absolute Error)\n",
    "mae = np.mean(np.abs(np.array(truth_values) - np.array(predicted_values)))\n",
    "\n",
    "# 输出结果\n",
    "print(f\"MAE (Mean Absolute Error): {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61bf6cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Mean Absolute Error): 55.35518095859286\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 设定参数 N\n",
    "N = 50\n",
    "\n",
    "# 初始化一个列表，用于存储每条 route 的总误差\n",
    "route_errors = []\n",
    "\n",
    "# 遍历 vehicle_edge_time_dict 中的每个 route_id\n",
    "for route_id, edge_time_dict in vehicle_edge_time_dict.items():\n",
    "    \n",
    "    # 获取该 route_id 下的所有 edge ids 列表\n",
    "    route_edges = list(edge_time_dict.keys())\n",
    "    \n",
    "    # 取前 N 个 edge ids，如果总长度小于 N，则取所有 edge\n",
    "    selected_edges = route_edges[:N]\n",
    "    \n",
    "    # 初始化该 route 的总误差\n",
    "    route_total_error = 0\n",
    "    \n",
    "    # 遍历每一个 edge，分别计算每个 edge 的 travel time 的绝对误差\n",
    "    for edge_id in selected_edges:\n",
    "        # 真实值：Travel_Time\n",
    "        truth_travel_time = edge_time_dict[edge_id]['Travel_Time']\n",
    "        \n",
    "        # 预测值：从 average_travel_time_dict 获取，如果没有，则默认值为 0\n",
    "        predicted_travel_time = average_travel_time_dict.get(edge_id, 0)\n",
    "        \n",
    "        # 计算该 edge 的绝对误差\n",
    "        edge_error = abs(truth_travel_time - predicted_travel_time)\n",
    "        \n",
    "        # 将该 edge 的误差累加到该 route 的总误差中\n",
    "        route_total_error += edge_error\n",
    "    \n",
    "    # 将该 route 的总误差添加到列表中\n",
    "    route_errors.append(route_total_error)\n",
    "\n",
    "# 计算 MAE (Mean Absolute Error)，对所有 route 的误差取平均值\n",
    "mae = np.mean(route_errors)\n",
    "\n",
    "# 输出结果\n",
    "print(f\"MAE (Mean Absolute Error): {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08449402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6177c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 生成输入的 route，query，以及 travel time 数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f75680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同时生成 route 数据和 time 数据的代码\n",
    "# route.txt 中，每行第一个值是 node 长度，其次是 start_node 以及对应的时间 bool 信息\n",
    "# time.txt 中，每行第一个值是 vehicle id，travel time 值的长度，以及后面的 travel time 值作为 truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f023aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 先根据 route_id 对 vehicle_edge_time_dict 进行排序\n",
    "vehicle_edge_time_dict = dict(sorted(vehicle_edge_time_dict.items(), key=lambda item: item[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ccd6ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to route.txt and time.txt\n"
     ]
    }
   ],
   "source": [
    "# 打开 route.txt 文件进行写入\n",
    "with open('route.txt', 'w') as route_file, open('time.txt', 'w') as time_file:\n",
    "    \n",
    "    # 遍历 vehicle_edge_time_dict 中的每个 route_id\n",
    "    for idx, (route_id, edge_time_dict) in enumerate(vehicle_edge_time_dict.items()):\n",
    "        \n",
    "        # 判断 idx 是否与 route_id 相等\n",
    "        if idx+1 != route_id:\n",
    "            print(f\"Mismatch: idx {idx} does not match route_id {route_id}\")\n",
    "        \n",
    "        # 获取该 route_id 下的所有 edge ids 列表\n",
    "        edge_ids = list(edge_time_dict.keys())\n",
    "        \n",
    "        # 写入 route.txt 文件中的 edge ids 长度\n",
    "        route_file.write(f\"{len(edge_ids) + 1} \")  # +1 因为我们需要最后写入 second_node\n",
    "        \n",
    "        # 写入 time.txt 文件的 route_id 和 edge ids 的长度\n",
    "        # time_file.write(f\"{route_id} {len(edge_ids)} \")\n",
    "        time_file.write(f\"{len(edge_ids)} \")\n",
    "        \n",
    "        # 遍历每个 edge_id，获取对应的时间数据\n",
    "        for edge_id in edge_ids:\n",
    "            # 使用 edge_to_int 将 edge_id 转换为整数\n",
    "            if edge_id in edge_to_int:\n",
    "                edge_int = edge_to_int[edge_id]\n",
    "            else:\n",
    "                # 如果 edge_id 不在 edge_to_int 中，打印错误信息并跳过该 edge_id\n",
    "                print(f\"Error: edge_id {edge_id} 不存在于 edge_to_int 词典中\")\n",
    "                continue  # 跳过该 edge_id\n",
    "            \n",
    "            # 使用 edge_to_nodes_mapped 词典将 edge_int 转换为 node pair\n",
    "            if edge_int in edge_to_nodes_mapped:\n",
    "                first_node, second_node = edge_to_nodes_mapped[edge_int]\n",
    "            else:\n",
    "                # 如果 edge_int 不在 edge_to_nodes_mapped 中，打印错误信息并跳过该 edge_id\n",
    "                print(f\"Error: edge_int {edge_int} 不存在于 edge_to_nodes_mapped 词典中\")\n",
    "                continue  # 跳过该 edge_id\n",
    "            \n",
    "            # 获取该 edge 的时间数据\n",
    "            delay_time = edge_time_dict[edge_id]['Delay_Time']\n",
    "            low_speed_time = edge_time_dict[edge_id]['LowSpee_Time']\n",
    "            wait_time = edge_time_dict[edge_id]['Wait_Time']\n",
    "            travel_time = edge_time_dict[edge_id]['Travel_Time']\n",
    "            \n",
    "            # 将 first_node 及其 Delay_Time, LowSpee_Time, Wait_Time 写入 route.txt 文件\n",
    "            route_file.write(f\"{int(first_node)} {delay_time} {low_speed_time} {wait_time} \")\n",
    "            \n",
    "            # 将 Travel_Time 写入 time.txt 文件\n",
    "            time_file.write(f\"{travel_time} \")\n",
    "        \n",
    "        # 最后一个 edge 的 second_node 写入 route.txt 文件，三个时间值都赋 0\n",
    "        if edge_ids:\n",
    "            route_file.write(f\"{int(second_node)} 0 0 0 \")\n",
    "        \n",
    "        # 每条 route 处理完后换行\n",
    "        route_file.write('\\n')\n",
    "        time_file.write('\\n')\n",
    "\n",
    "print(\"Data has been written to route.txt and time.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e987fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始写入 query 数据的代码，但是没有经过验证\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a69e2495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to query.txt\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "写入 routes 的 query 数据\n",
    "'''\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('Manhattan_trajectory_mapped_node.csv')\n",
    "\n",
    "df = df.sort_values(by='route_id')\n",
    "\n",
    "# 打开一个新的文本文件用于写入数据\n",
    "with open('query.txt', 'w') as file:\n",
    "    # 遍历 DataFrame 中的每一行\n",
    "    for index, row in df.iterrows():\n",
    "        # 提取出发节点和目的地节点，并将它们转换为整数\n",
    "        node_sequence = row['route_by_mappped_node'].split()\n",
    "        departure_node = int(float(node_sequence[0]))  # 先转换为浮点数，再转换为整数\n",
    "        destination_node = int(float(node_sequence[-1]))\n",
    "\n",
    "        # 提取出发时间并转换为整数\n",
    "        departure_time = int(row['depart_time'])\n",
    "\n",
    "        # 将提取的信息按格式写入文件\n",
    "        file.write(f\"{departure_node} {destination_node} {departure_time}\\n\")\n",
    "\n",
    "print(\"Data has been written to query.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf7661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始写入 query 数据的代码 + 验证步骤\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2fc7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('Manhattan_trajectory_mapped_node.csv')\n",
    "\n",
    "df = df.sort_values(by='route_id')\n",
    "\n",
    "# 打开一个新的文本文件用于写入数据\n",
    "with open('query.txt', 'w') as file:\n",
    "    # 遍历 DataFrame 中的每一行\n",
    "    for index, row in df.iterrows():\n",
    "        # 提取出发节点和目的地节点，并将它们转换为整数\n",
    "        node_sequence = row['route_by_mappped_node'].split()\n",
    "        departure_node = int(float(node_sequence[0]))  # 先转换为浮点数，再转换为整数\n",
    "        destination_node = int(float(node_sequence[-1]))\n",
    "\n",
    "        # 提取出发时间并转换为整数\n",
    "        departure_time = int(row['depart_time'])\n",
    "\n",
    "        # 获取当前 route_id\n",
    "        route_id = row['route_id']\n",
    "        \n",
    "        # 通过 vehicle_edge_time_dict 获取该 route 的首尾 edge\n",
    "        if route_id in vehicle_edge_time_dict:\n",
    "            edge_ids = list(vehicle_edge_time_dict[route_id].keys())\n",
    "            \n",
    "            # 首个和最后一个 edge_id\n",
    "            first_edge = edge_ids[0]\n",
    "            last_edge = edge_ids[-1]\n",
    "            \n",
    "            # 获取首个 edge 的 first_node 和最后一个 edge 的 second_node\n",
    "            if first_edge in edge_to_int and last_edge in edge_to_int:\n",
    "                first_edge_int = edge_to_int[first_edge]\n",
    "                last_edge_int = edge_to_int[last_edge]\n",
    "                \n",
    "                if first_edge_int in edge_to_nodes_mapped and last_edge_int in edge_to_nodes_mapped:\n",
    "                    first_node = edge_to_nodes_mapped[first_edge_int][0]  # 获取 first_node\n",
    "                    second_node = edge_to_nodes_mapped[last_edge_int][1]  # 获取 second_node\n",
    "                else:\n",
    "                    print(f\"Error: Edge {first_edge_int} or {first_edge_int} 不存在于 edge_to_int 词典中\")\n",
    "                    continue\n",
    "            else:\n",
    "                print(f\"Error: Edge {first_edge} or {last_edge} 不存在于 edge_to_int 词典中\")\n",
    "                continue  # 跳过该行\n",
    "            \n",
    "            # 验证 departure_node 和 destination_node 是否与首尾 node 相同\n",
    "            if first_node != departure_node:\n",
    "                print(f\"Error: route_id {route_id} 的 departure_node 不匹配: 文件中的 {departure_node}, 词典中的 {first_node}\")\n",
    "            if second_node != destination_node:\n",
    "                print(f\"Error: route_id {route_id} 的 destination_node 不匹配: 文件中的 {destination_node}, 词典中的 {second_node}\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"Error: route_id {route_id} 不存在于 vehicle_edge_time_dict 中\")\n",
    "            continue  # 跳过该行\n",
    "\n",
    "        # 将提取的信息按格式写入文件\n",
    "        file.write(f\"{departure_node} {destination_node} {departure_time}\\n\")\n",
    "\n",
    "print(\"Data has been written to query.txt\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c35eac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to route.txt\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "写入 routes 的 route 数据\n",
    "'''\n",
    "\n",
    "'''\n",
    "# Capture route and stored into .txt file\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('Manhattan_trajectory_mapped_node.csv')\n",
    "\n",
    "df = df.sort_values(by='route_id')\n",
    "\n",
    "# 打开一个新的文本文件用于写入数据\n",
    "with open('route.txt', 'w') as file:\n",
    "    # 遍历 DataFrame 中的每一行\n",
    "    for index, row in df.iterrows():\n",
    "        # 分割 node ID 序列并将每个节点 ID 转换为整数\n",
    "        node_sequence = [int(float(node_id)) for node_id in row['route_by_mappped_node'].split()]\n",
    "        node_count = len(node_sequence)\n",
    "\n",
    "        # 将节点数量和整数形式的节点序列按格式写入文件\n",
    "        file.write(f\"{node_count} {' '.join(map(str, node_sequence))}\\n\")\n",
    "\n",
    "print(\"Data has been written to route.txt\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e0c95b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to time_counts_and_values.txt\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "生成每个 edge 上对应出行时间的统计，\n",
    "但是，包含车辆在红绿灯的等待时间，对我们希望忽略等待时间的影响的问题暂时没有帮助\n",
    "'''\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('Manhattan_trajectory_mapped_node.csv')\n",
    "\n",
    "# 打开一个新的文本文件用于写入数据\n",
    "with open('time_counts_and_values.txt', 'w') as file:\n",
    "    # 遍历 DataFrame 中的每一行\n",
    "    for index, row in df.iterrows():\n",
    "        # 分割时间数据并将每个时间数据转换为整数\n",
    "        time_sequence = [int(float(time)) for time in row['exit_times'].split()]\n",
    "        time_count = len(time_sequence)\n",
    "\n",
    "        # 将时间数量和整数形式的时间数据按格式写入文件\n",
    "        file.write(f\"{time_count} {' '.join(map(str, time_sequence))}\\n\")\n",
    "\n",
    "print(\"Data has been written to time_counts_and_values.txt\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6165d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8115429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\nimport os\\n\\n#获取xml文件地址\\npath = os.path.abspath(\\'./../../SUMO_data_generation/\\') \\n#获取xml文件地址\\ndata_path = os.path.join(path,\\'TraCI_output_adjusted.csv\\') \\n\\n\\n# 载入CSV文件\\ndf = pd.read_csv(data_path)\\n\\ndf[\\'Travel_Time\\'] = pd.to_numeric(df[\\'Travel_Time\\'], errors=\\'coerce\\') +                     pd.to_numeric(df[\\'Delay_Time\\'], errors=\\'coerce\\') +                     pd.to_numeric(df[\\'LowSpee_Time\\'], errors=\\'coerce\\') \\n\\ndf.loc[df[\\'E_Length\\'] / df[\\'Speed_Net\\'] < 1, \\'Travel_Time\\'] = 0\\n\\n# 将这 \\'Delay_Time\\', \\'LowSpee_Time\\', \\'Wait_Time\\' 转换为 0 和 1 的形式\\ndf[[\\'Delay_Time\\', \\'LowSpee_Time\\', \\'Wait_Time\\']] = df[[\\'Delay_Time\\', \\'LowSpee_Time\\', \\'Wait_Time\\']].applymap(lambda x: 0 if x == 0 else 1)\\n\\n\\n# 构建一个词典嵌套词典 vehicle_edge_time_dict，外层 key 是 df 中的 \\'Vehicle_ID\\'，value 是 \\'Edge_ID\\', \\n# 内层词典 key 是 \\'Edge_ID\\'，value 是 \\'Delay_Time\\', \\'LowSpee_Time\\', \\'Wait_Time\\', \\'Travel_Time\\'\\n\\n# 任务 1:\\n\\n# 设定参数N（计算每个Vehicle_ID的前N个Travel_Time的和）\\nN = 50  \\n\\n# 对于相同 vehicle id 对应的 vehicle_route_dict 和 vehicle_edge_time_dict，比较其 edge ids，\\n# 由于 vehicle_route_dict 的 edge ids 包含 vehicle_edge_time_dict 对应的 edge ids，\\n# 在 vehicle_route_dict 中找到第 N 个作为 target_id，在 vehicle_edge_time_dict 对应的 edge ids 中找到 target_id，\\n# 如果 target_id 在 edge ids 中的位置大于 N，打印报错，\\n# 合并 target_id 在 edge ids 中的所有 travel time 的和作为该 vehicle id 对应的 travel time，\\n# 并存入一个新的词典中，key 是 vehcile id，value 是 travel time\\n\\n\\n\\n\\n# 分组并计算每个组的Travel_Time和\\ngrouped = df.groupby(\\'Vehicle_ID\\')[\\'Travel_Time\\'].apply(lambda x: x.head(N).sum()).reset_index()\\n\\n# 按照 Vehicle_ID 进行排序\\ngrouped = grouped.sort_values(by=\\'Vehicle_ID\\')\\n\\n# 计算Vehicle_ID的unique值的数量\\nunique_vehicle_ids = len(grouped)\\n\\n# 准备要写入文件的数据\\nlines = [f\"{unique_vehicle_ids} {N}\\n\"]\\nlines += [f\"{row[\\'Vehicle_ID\\']} {row[\\'Travel_Time\\']}\\n\" for index, row in grouped.iterrows()]\\n\\n# 写入到文本文件\\nwith open(\\'time_no_wait.txt\\', \\'w\\') as f:\\n    f.writelines(lines)\\n\\nprint(f\"数据处理完成，保留 {N} 长度的 route 数据写入 time_no_wait.txt文件。\")\\n'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "生成处理短路径后的每条 route 的 travel time 作为 truth：可以设定 edges 长度\n",
    "'''\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#获取xml文件地址\n",
    "path = os.path.abspath('./../../SUMO_data_generation/') \n",
    "#获取xml文件地址\n",
    "data_path = os.path.join(path,'TraCI_output_adjusted.csv') \n",
    "\n",
    "\n",
    "# 载入CSV文件\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "df['Travel_Time'] = pd.to_numeric(df['Travel_Time'], errors='coerce') + \\\n",
    "                    pd.to_numeric(df['Delay_Time'], errors='coerce') + \\\n",
    "                    pd.to_numeric(df['LowSpee_Time'], errors='coerce') \n",
    "\n",
    "df.loc[df['E_Length'] / df['Speed_Net'] < 1, 'Travel_Time'] = 0\n",
    "\n",
    "# 将这 'Delay_Time', 'LowSpee_Time', 'Wait_Time' 转换为 0 和 1 的形式\n",
    "df[['Delay_Time', 'LowSpee_Time', 'Wait_Time']] = df[['Delay_Time', 'LowSpee_Time', 'Wait_Time']].applymap(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "\n",
    "# 构建一个词典嵌套词典 vehicle_edge_time_dict，外层 key 是 df 中的 'Vehicle_ID'，value 是 'Edge_ID', \n",
    "# 内层词典 key 是 'Edge_ID'，value 是 'Delay_Time', 'LowSpee_Time', 'Wait_Time', 'Travel_Time'\n",
    "\n",
    "# 任务 1:\n",
    "\n",
    "# 设定参数N（计算每个Vehicle_ID的前N个Travel_Time的和）\n",
    "N = 50  \n",
    "\n",
    "# 对于相同 vehicle id 对应的 vehicle_route_dict 和 vehicle_edge_time_dict，比较其 edge ids，\n",
    "# 由于 vehicle_route_dict 的 edge ids 包含 vehicle_edge_time_dict 对应的 edge ids，\n",
    "# 在 vehicle_route_dict 中找到第 N 个作为 target_id，在 vehicle_edge_time_dict 对应的 edge ids 中找到 target_id，\n",
    "# 如果 target_id 在 edge ids 中的位置大于 N，打印报错，\n",
    "# 合并 target_id 在 edge ids 中的所有 travel time 的和作为该 vehicle id 对应的 travel time，\n",
    "# 并存入一个新的词典中，key 是 vehcile id，value 是 travel time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 分组并计算每个组的Travel_Time和\n",
    "grouped = df.groupby('Vehicle_ID')['Travel_Time'].apply(lambda x: x.head(N).sum()).reset_index()\n",
    "\n",
    "# 按照 Vehicle_ID 进行排序\n",
    "grouped = grouped.sort_values(by='Vehicle_ID')\n",
    "\n",
    "# 计算Vehicle_ID的unique值的数量\n",
    "unique_vehicle_ids = len(grouped)\n",
    "\n",
    "# 准备要写入文件的数据\n",
    "lines = [f\"{unique_vehicle_ids} {N}\\n\"]\n",
    "lines += [f\"{row['Vehicle_ID']} {row['Travel_Time']}\\n\" for index, row in grouped.iterrows()]\n",
    "\n",
    "# 写入到文本文件\n",
    "with open('time_no_wait.txt', 'w') as f:\n",
    "    f.writelines(lines)\n",
    "\n",
    "print(f\"数据处理完成，保留 {N} 长度的 route 数据写入 time_no_wait.txt文件。\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8f6b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c648dc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records number is: 3597154\n",
      "Small edge number is: 1709371\n",
      "数据处理完成，完整 route 数据写入 time_no_wait.txt文件。\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "生成处理短路径后的每条 route 的 travel time 作为 truth：默认 edges 长度\n",
    "'''\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#获取xml文件地址\n",
    "path = os.path.abspath('./../../SUMO_data_generation/') \n",
    "#获取xml文件地址\n",
    "data_path = os.path.join(path,'TraCI_output_adjusted.csv') \n",
    "\n",
    "\n",
    "# 载入CSV文件\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f'Records number is: {len(df)}')\n",
    "\n",
    "df.loc[df['E_Length'] / df['Speed_Net'] < 1, 'Travel_Time'] = 0\n",
    "\n",
    "print(f\"Small edge number is: {(df['E_Length'] / df['Speed_Net'] < 1).sum()}\")\n",
    "\n",
    "# 设定参数N（None表示计算所有Travel_Time的和）\n",
    "N = None  # 您可以根据需要更改这个值或设置为具体的数字\n",
    "\n",
    "# 分组并计算每个组的Travel_Time和，根据N的值决定计算方式\n",
    "if N is None:\n",
    "    grouped = df.groupby('Vehicle_ID')['Travel_Time'].sum().reset_index()\n",
    "else:\n",
    "    grouped = df.groupby('Vehicle_ID')['Travel_Time'].apply(lambda x: x.head(N).sum()).reset_index()\n",
    "    \n",
    "# 按照 Vehicle_ID 进行排序\n",
    "grouped = grouped.sort_values(by='Vehicle_ID')\n",
    "\n",
    "# 计算Vehicle_ID的unique值的数量\n",
    "unique_vehicle_ids = len(grouped)\n",
    "\n",
    "# 准备要写入文件的数据\n",
    "lines = [f\"{unique_vehicle_ids} {N if N is not None else 0}\\n\"]\n",
    "lines += [f\"{row['Vehicle_ID']} {row['Travel_Time']}\\n\" for index, row in grouped.iterrows()]\n",
    "\n",
    "\n",
    "# 写入到文本文件\n",
    "with open('time_no_wait.txt', 'w') as f:\n",
    "    f.writelines(lines)\n",
    "\n",
    "print(\"数据处理完成，完整 route 数据写入 time_no_wait.txt文件。\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b39762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "328ecf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records number is: 39845224\n",
      "Small edge number is: 18851703\n",
      "Max travel time is: 2362\n",
      "Min travel time is: 1\n",
      "Travel time range difference is: 2361\n",
      "\n",
      " Trave time for each route is:\n",
      "        Vehicle_ID  Travel_Time\n",
      "0                0          985\n",
      "1                1          371\n",
      "2                2         1054\n",
      "3                3          286\n",
      "4                4          455\n",
      "...            ...          ...\n",
      "177682      177682          829\n",
      "177683      177683          173\n",
      "177684      177684          591\n",
      "177685      177685         1456\n",
      "177686      177686          233\n",
      "\n",
      "[177687 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "route 出行时间的统计\n",
    "'''\n",
    "\n",
    "'''\n",
    "#获取xml文件地址\n",
    "path = os.path.abspath('./../../SUMO_data_generation/') \n",
    "#获取xml文件地址\n",
    "data_path = os.path.join(path,'TraCI_output_adjusted.csv') \n",
    "\n",
    "\n",
    "# 载入CSV文件\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f'Records number is: {len(df)}')\n",
    "\n",
    "df.loc[df['E_Length'] / df['Speed_Net'] < 1, 'Travel_Time'] = 0\n",
    "\n",
    "print(f\"Small edge number is: {(df['E_Length'] / df['Speed_Net'] < 1).sum()}\")\n",
    "\n",
    "\n",
    "# 设定参数N（None表示计算所有Travel_Time的和）\n",
    "N = None  # 您可以根据需要更改这个值或设置为具体的数字\n",
    "\n",
    "# 分组并计算每个组的Travel_Time和，根据N的值决定计算方式\n",
    "if N is None:\n",
    "    grouped = df.groupby('Vehicle_ID')['Travel_Time'].sum().reset_index()\n",
    "else:\n",
    "    grouped = df.groupby('Vehicle_ID')['Travel_Time'].apply(lambda x: x.head(N).sum()).reset_index()\n",
    "    \n",
    "print(f'Max travel time is: {grouped[\"Travel_Time\"].max()}')\n",
    "print(f'Min travel time is: {grouped[\"Travel_Time\"].min()}')\n",
    "print(f'Travel time range difference is: {grouped[\"Travel_Time\"].max() - grouped[\"Travel_Time\"].min()}')\n",
    "\n",
    "print(f'\\n Trave time for each route is:')\n",
    "print(grouped)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d53c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1ba70b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
