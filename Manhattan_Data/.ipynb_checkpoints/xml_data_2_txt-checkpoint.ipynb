{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e374a944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import os\n",
    "import time\n",
    "from xml.dom.minidom import parse\n",
    "import xml.dom.minidom\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "330fcdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path is: /Users/xuzizhuo/Desktop/Traffic Simulation Prediction/SUMO_data_generation/test.net.xml\n",
      "Number of edges are:  29497\n"
     ]
    }
   ],
   "source": [
    "# Capture network information from \".xml\" and save into \".csv\"\n",
    "\n",
    "def network_data_exploration(filename):\n",
    "    # Define path\n",
    "    path = os.path.abspath('./../../SUMO_data_generation/') \n",
    "    # Define data path\n",
    "    data_path = os.path.join(path,filename) \n",
    "    print('Data path is:', data_path) \n",
    "    \n",
    "    # Open \".xml\" and find data\n",
    "    DOMTree = xml.dom.minidom.parse(data_path) \n",
    "    data = DOMTree.documentElement \n",
    "    \n",
    "    # Get element list\n",
    "    nodeList = data.getElementsByTagName(\"edge\")\n",
    "    print(\"Number of edges are: \", len(nodeList))\n",
    "    \n",
    "    # Define and initilzie explored data\n",
    "    all_rows = []\n",
    "    \n",
    "    for node in nodeList: \n",
    "        # Get features of each edge\n",
    "        edge_ID = node.getAttribute(\"id\")\n",
    "        node_start = node.getAttribute(\"from\")\n",
    "        node_end = node.getAttribute(\"to\")\n",
    "        priority = node.getAttribute(\"priority\")\n",
    "        # Get element list of edge\n",
    "        subNodeList = node.getElementsByTagName(\"lane\")\n",
    "        \n",
    "        # Initialize features\n",
    "        speed = 0\n",
    "        length = 0\n",
    "        for subNode in subNodeList:\n",
    "            # Get features of each lane\n",
    "            speed += float(subNode.getAttribute(\"speed\"))\n",
    "        \n",
    "            length += float(subNode.getAttribute(\"length\"))\n",
    "        speed_avg = speed / len(subNodeList)\n",
    "        length_avg = length / len(subNodeList)\n",
    "        lane_num = len(subNodeList)\n",
    "            \n",
    "        newRow = {\"edge_id\": edge_ID, \"node_start\": node_start, \"node_end\": node_end, \"lane_num\":lane_num, \"speed\": speed_avg, \"length\": length_avg, \"priority\": priority}\n",
    "        all_rows.append(newRow)\n",
    "              \n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Call function to export network information data\n",
    "df = network_data_exploration(\"test.net.xml\")\n",
    "df.head()\n",
    "df.to_csv('Manhattan_network_raw.csv', index=False)\n",
    "\n",
    "# Potential mistakes:\n",
    "# Edges allow different types of vehicles but do not considered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00a3d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "把 string 结构的 node ID 转成 int 结构的：node_to_int，\n",
    "把 string 结构的 edge ID 转成 int 结构的：edge_to_int，\n",
    "把 int 结构的 edge ID 转成 string 结构的：int_to_edge，\n",
    "储存 int 结构的 node ID 和 edge ID 到 Manhattan_network_mapped.csv 中。\n",
    "'''\n",
    "\n",
    "\n",
    "# Map edge and node ID from 0 to their length\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv('Manhattan_network_raw.csv')\n",
    "\n",
    "# Convert unique string ids of \"node_start\" and \"node_end\" to unique integers.\n",
    "# Get a list of unique nodes\n",
    "unique_nodes = pd.concat([df['node_start'], df['node_end']]).unique()\n",
    "# Create a mapping of node string id to integer\n",
    "node_to_int = {node: idx for idx, node in enumerate(unique_nodes)}\n",
    "# Replace the string ids in the dataframe\n",
    "df['node_start'] = df['node_start'].map(node_to_int)\n",
    "df['node_end'] = df['node_end'].map(node_to_int)\n",
    "\n",
    "# Convert \"edge_id\" to unique integers.\n",
    "# Create a mapping of edge string id to integer\n",
    "edge_to_int = {edge: idx for idx, edge in enumerate(df['edge_id'].unique())}\n",
    "# Replace the string ids in the dataframe\n",
    "df['edge_id'] = df['edge_id'].map(edge_to_int)\n",
    "\n",
    "\n",
    "# 反转 edge_to_int 映射\n",
    "int_to_edge = {v: k for k, v in edge_to_int.items()}\n",
    "\n",
    "\n",
    "# Save mapped dataframe\n",
    "df.to_csv('Manhattan_network_mapped.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "213467bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "储存词典 edge_to_int 到本地文件。\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "def save_dict_to_file(dictionary, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(dictionary, f)\n",
    "\n",
    "save_dict_to_file(edge_to_int, 'edge_to_int.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f002ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "生成 int 结构 edge ID -> lane_num，speed_limit，average_length 的词典 edge_id_to_features，\n",
    "储存词典 edge_id_to_features 到 csv 文件，方便 C++ 读取。\n",
    "'''\n",
    "\n",
    "# 读取预处理后的数据\n",
    "df = pd.read_csv('Manhattan_network_mapped.csv')\n",
    "\n",
    "# 初始化一个空字典来存储整数 edge_id 映射到其特征的信息\n",
    "edge_id_to_features = {}\n",
    "\n",
    "# 遍历 DataFrame 的每一行\n",
    "for index, row in df.iterrows():\n",
    "    # 为当前 edge_id 存储 lane_num, speed, 和 length 的信息\n",
    "    edge_id_to_features[row['edge_id']] = {\n",
    "        \"lane_num\": row['lane_num'],\n",
    "        \"speed\": row['speed'],\n",
    "        \"length\": row['length']\n",
    "    }\n",
    "\n",
    "# 将字典保存为 CSV 文件\n",
    "with open('edge_id_to_features.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"edge_id\", \"lane_num\", \"speed\", \"length\"])  # 写入标题\n",
    "    for edge_id, features in edge_id_to_features.items():\n",
    "        writer.writerow([edge_id, features['lane_num'], features['speed'], features['length']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ceea0fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e4e39829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge to Nodes Mapping: (7480410399, 42437990)\n",
      "Nodes to Edge Mapping: -1004369132#0\n"
     ]
    }
   ],
   "source": [
    "# Map edge to node pairs & node pairs to edges\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('Manhattan_network_raw.csv')\n",
    "\n",
    "# 初始化两个字典\n",
    "edge_to_nodes_raw = {}  # edge_id 映射到 node_start 和 node_end\n",
    "nodes_to_edge_raw = {}  # node_start 和 node_end 映射到 edge_id\n",
    "\n",
    "# 遍历 DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    edge_id = row['edge_id']\n",
    "    node_start = row['node_start']\n",
    "    node_end = row['node_end']\n",
    "\n",
    "    # 建立 edge_id 到 node_start 和 node_end 的映射\n",
    "    edge_to_nodes_raw[edge_id] = (node_start, node_end)\n",
    "\n",
    "    # 建立 node_start 和 node_end 到 edge_id 的映射\n",
    "    nodes_to_edge_raw[(node_start, node_end)] = edge_id\n",
    "\n",
    "# 测试输出\n",
    "print(\"Edge to Nodes Mapping:\", edge_to_nodes_raw[\"-1004369132#0\"])\n",
    "print(\"Nodes to Edge Mapping:\", nodes_to_edge_raw[(7480410399, 42437990)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90d0a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map edge to node pairs & node pairs to edges\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('Manhattan_network_mapped.csv')\n",
    "\n",
    "# 初始化两个字典\n",
    "edge_to_nodes_mapped = {}  # edge_id 映射到 node_start 和 node_end\n",
    "nodes_to_edge_mapped = {}  # node_start 和 node_end 映射到 edge_id\n",
    "\n",
    "# 遍历 DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    edge_id = row['edge_id']\n",
    "    node_start = row['node_start']\n",
    "    node_end = row['node_end']\n",
    "\n",
    "    # 建立 edge_id 到 node_start 和 node_end 的映射\n",
    "    edge_to_nodes_mapped[edge_id] = (node_start, node_end)\n",
    "\n",
    "    # 建立 node_start 和 node_end 到 edge_id 的映射\n",
    "    nodes_to_edge_mapped[(node_start, node_end)] = edge_id\n",
    "\n",
    "# 测试输出\n",
    "# print(\"Edge to Nodes Mapping:\", edge_to_nodes_mapped[0])\n",
    "# print(\"Nodes to Edge Mapping:\", nodes_to_edge_mapped[(0, 9115)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "42c91880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'46201646'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_to_edge_mapped[(12573, 9504)]\n",
    "int_to_edge[16133]\n",
    "\n",
    "# edge id=\"46201646\" from=\"370913784\" to=\"370914027\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74e1585d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'960097006'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_to_edge_mapped[(9504, 9520)]\n",
    "int_to_edge[28341]\n",
    "\n",
    "# edge id=\"960097006\" from=\"370914027\" to=\"589099584\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053c2f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fadae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52bb75b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of unqiue nodes:  20859\n",
      "Length of unique edges:  29497\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# Paths for the input and output files\n",
    "csv_file_path = 'Manhattan_network_mapped.csv'\n",
    "txt_file_path1 = 'Manhattan_network_BJ.txt'\n",
    "txt_file_path2 = 'Manhattan_network_min_Travel_Time.txt'\n",
    "\n",
    "# Loading the CSV file\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Calculating unique nodes and edges\n",
    "unique_nodes = pd.concat([df['node_start'], df['node_end']]).unique()\n",
    "unique_edges = df['edge_id'].unique()\n",
    "\n",
    "# The two integer values to be added at the beginning of each .txt file\n",
    "int_val_1 = len(unique_nodes)\n",
    "print(\"Length of unqiue nodes: \", len(unique_nodes))\n",
    "int_val_2 = len(unique_edges)\n",
    "print(\"Length of unique edges: \", len(unique_edges))\n",
    "\n",
    "# Generating the first .txt file\n",
    "with open(txt_file_path1, 'w') as txt_file1:\n",
    "    # Writing the two integers to the TXT file\n",
    "    txt_file1.write(f\"{int(int_val_1)} {int(int_val_2)}\\n\")\n",
    "    \n",
    "    # Iterating over rows in the DataFrame to format and write each row according to specifications\n",
    "    for index, row in df.iterrows():\n",
    "        txt_file1.write(f\"{int(row['node_start'])} {int(row['node_end'])} {int(row['edge_id'])} {round(row['length'],2)}\\n\")\n",
    "\n",
    "# Generating the second .txt file\n",
    "with open(txt_file_path2, 'w') as txt_file2:\n",
    "    # Writing the two integers to the TXT file\n",
    "    txt_file2.write(f\"{int(int_val_1)} {int(int_val_2)}\\n\")\n",
    "    \n",
    "    # Iterating over rows in the DataFrame to format and write each row according to specifications\n",
    "    for index, row in df.iterrows():\n",
    "        travel_time = round(row['length'] / row['speed'],2)  # Calculating travel time as length_avg / speed_avg\n",
    "        txt_file2.write(f\"{int(row['node_start'])} {int(row['node_end'])} {travel_time}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc91034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b64bd02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ba79b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of routes are:  89\n"
     ]
    }
   ],
   "source": [
    "# Capture trajectory data from \".xml\" file to \".csv\" file\n",
    "\n",
    "def trajectory_information_capture(filename):\n",
    "    #获取xml文件地址\n",
    "    path = os.path.abspath('./../../SUMO_data_generation') \n",
    "    #获取xml文件地址\n",
    "    data_path = os.path.join(path,filename) \n",
    "    \n",
    "    # 打开xml文档\n",
    "    DOMTree = xml.dom.minidom.parse(data_path) \n",
    "    # 根据xml文档，得到文档元素的对象\n",
    "    data = DOMTree.documentElement \n",
    "    \n",
    "    # 获取节点列表\n",
    "    nodeList = data.getElementsByTagName(\"vehicle\")\n",
    "    # 定义route数量\n",
    "    nodeLen = len(nodeList)\n",
    "    print(\"Length of routes are: \", nodeLen)\n",
    "    \n",
    "    all_rows = []\n",
    "    \n",
    "    for node in nodeList: \n",
    "        # 获取当前节点属性值\n",
    "        route_ID = node.getAttribute(\"id\")\n",
    "        depart_time = node.getAttribute(\"depart\")\n",
    "        arrival_time = node.getAttribute(\"arrival\")\n",
    "        \n",
    "        subNodeList = node.getElementsByTagName(\"route\")\n",
    "        \n",
    "        for subNode in subNodeList:\n",
    "            if len(subNodeList) != 1:\n",
    "                print(\"Error.\")\n",
    "            \n",
    "            # 获取当前节点属性值\n",
    "            route = subNode.getAttribute(\"edges\")\n",
    "            exit_times = subNode.getAttribute(\"exitTimes\")\n",
    "            # 拆分字符串\n",
    "            ids = route.split()\n",
    "            # 提取第一个和最后一个ID\n",
    "            start_node = ids[0]\n",
    "            end_node = ids[-1]\n",
    "        \n",
    "        newRow = {\"route_id\": route_ID, \"depart_time\": depart_time, \"arrival_time\": arrival_time, \n",
    "                  \"start_edge\": start_node, \"end_edge\": end_node, \"route_by_edge\": route, \"exit_times\": exit_times}\n",
    "        all_rows.append(newRow)\n",
    "\n",
    "    # Convert list of dictionaries to DataFrame\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    return df\n",
    "\n",
    "df_trajectory = trajectory_information_capture(\"outputfile.xml\")\n",
    "df_trajectory.to_csv('Manhattan_trajectory_raw.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a8f960b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>depart_time</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>start_edge</th>\n",
       "      <th>end_edge</th>\n",
       "      <th>route_by_edge</th>\n",
       "      <th>exit_times</th>\n",
       "      <th>route_by_mappped_node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>53.0</td>\n",
       "      <td>309.0</td>\n",
       "      <td>254594899</td>\n",
       "      <td>815957441#0</td>\n",
       "      <td>254594899 243046576#0 243046576#1 -1013655882#...</td>\n",
       "      <td>71.00 76.00 90.00 92.00 99.00 103.00 106.00 11...</td>\n",
       "      <td>4302.0 1808.0 9070.0 28.0 27.0 26.0 25.0 24.0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>-196116967#1</td>\n",
       "      <td>33117604</td>\n",
       "      <td>-196116967#1 -196116967#0 -455687907#22 -45568...</td>\n",
       "      <td>90.00 99.00 102.00 102.00 103.00 106.00 106.00...</td>\n",
       "      <td>977.0 665.0 2287.0 2286.0 2285.0 2283.0 2282.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>82.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>5671090</td>\n",
       "      <td>1025731530#1</td>\n",
       "      <td>5671090 760727197 760727187#0 760727187#1 1080...</td>\n",
       "      <td>91.00 98.00 101.00 102.00 103.00 106.00 109.00...</td>\n",
       "      <td>15920.0 18700.0 18698.0 18699.0 6187.0 209.0 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>142.0</td>\n",
       "      <td>489.0</td>\n",
       "      <td>243046575#5</td>\n",
       "      <td>978645353#1</td>\n",
       "      <td>243046575#5 243046575#6 243046575#7 243046575#...</td>\n",
       "      <td>144.00 154.00 165.00 166.00 167.00 168.00 187....</td>\n",
       "      <td>4098.0 9067.0 9068.0 9069.0 20385.0 20386.0 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>-481047237#1</td>\n",
       "      <td>421830414</td>\n",
       "      <td>-481047237#1 -481047237#0 -5672138#5 -5672138#...</td>\n",
       "      <td>17.00 17.00 18.00 33.00 35.00 36.00 44.00 52.0...</td>\n",
       "      <td>2828.0 2827.0 3591.0 3590.0 3589.0 3588.0 7339...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   route_id  depart_time  arrival_time    start_edge      end_edge  \\\n",
       "0         7         53.0         309.0     254594899   815957441#0   \n",
       "1         8         60.0         376.0  -196116967#1      33117604   \n",
       "2        11         82.0         389.0       5671090  1025731530#1   \n",
       "3        19        142.0         489.0   243046575#5   978645353#1   \n",
       "4         1          8.0         499.0  -481047237#1     421830414   \n",
       "\n",
       "                                       route_by_edge  \\\n",
       "0  254594899 243046576#0 243046576#1 -1013655882#...   \n",
       "1  -196116967#1 -196116967#0 -455687907#22 -45568...   \n",
       "2  5671090 760727197 760727187#0 760727187#1 1080...   \n",
       "3  243046575#5 243046575#6 243046575#7 243046575#...   \n",
       "4  -481047237#1 -481047237#0 -5672138#5 -5672138#...   \n",
       "\n",
       "                                          exit_times  \\\n",
       "0  71.00 76.00 90.00 92.00 99.00 103.00 106.00 11...   \n",
       "1  90.00 99.00 102.00 102.00 103.00 106.00 106.00...   \n",
       "2  91.00 98.00 101.00 102.00 103.00 106.00 109.00...   \n",
       "3  144.00 154.00 165.00 166.00 167.00 168.00 187....   \n",
       "4  17.00 17.00 18.00 33.00 35.00 36.00 44.00 52.0...   \n",
       "\n",
       "                               route_by_mappped_node  \n",
       "0  4302.0 1808.0 9070.0 28.0 27.0 26.0 25.0 24.0 ...  \n",
       "1  977.0 665.0 2287.0 2286.0 2285.0 2283.0 2282.0...  \n",
       "2  15920.0 18700.0 18698.0 18699.0 6187.0 209.0 2...  \n",
       "3  4098.0 9067.0 9068.0 9069.0 20385.0 20386.0 20...  \n",
       "4  2828.0 2827.0 3591.0 3590.0 3589.0 3588.0 7339...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert raw edge IDs constructed route into mapped node IDs\n",
    "# e.g. raw_edge_1 raw_edge_2 ... -> mapped_node_1 mapped_node_2 mapped_node_3\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('Manhattan_trajectory_raw.csv')\n",
    "\n",
    "# 初始化新列\n",
    "df['route_by_mappped_node'] = None\n",
    "\n",
    "# 遍历 DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # 分割 route_by_edge 字符串并应用映射\n",
    "    node_pairs = [edge_to_nodes_mapped[edge_to_int[edge_id]] for edge_id in row['route_by_edge'].split(' ') if edge_id in edge_to_int]\n",
    "\n",
    "    # 处理节点序列，确保节点不重复\n",
    "    node_sequence = []\n",
    "    for pair in node_pairs:\n",
    "        # 确保节点转换为字符串\n",
    "        node_start = str(pair[0])\n",
    "        node_end = str(pair[1])\n",
    "\n",
    "        if not node_sequence or node_sequence[-1] != node_start:\n",
    "            node_sequence.append(node_start)\n",
    "        node_sequence.append(node_end)\n",
    "\n",
    "    # 更新新列\n",
    "    df.at[index, 'route_by_mappped_node'] = ' '.join(node_sequence)\n",
    "\n",
    "# 保存到新的 CSV 文件\n",
    "df.to_csv('Manhattan_trajectory_mapped_node.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a69e2495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to query.txt\n"
     ]
    }
   ],
   "source": [
    "# Capture query and stored into .txt file\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('Manhattan_trajectory_mapped_node.csv')\n",
    "\n",
    "# 打开一个新的文本文件用于写入数据\n",
    "with open('query.txt', 'w') as file:\n",
    "    # 遍历 DataFrame 中的每一行\n",
    "    for index, row in df.iterrows():\n",
    "        # 提取出发节点和目的地节点，并将它们转换为整数\n",
    "        node_sequence = row['route_by_mappped_node'].split()\n",
    "        departure_node = int(float(node_sequence[0]))  # 先转换为浮点数，再转换为整数\n",
    "        destination_node = int(float(node_sequence[-1]))\n",
    "\n",
    "        # 提取出发时间并转换为整数\n",
    "        departure_time = int(row['depart_time'])\n",
    "\n",
    "        # 将提取的信息按格式写入文件\n",
    "        file.write(f\"{departure_node} {destination_node} {departure_time}\\n\")\n",
    "\n",
    "print(\"Data has been written to query.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c35eac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to route.txt\n"
     ]
    }
   ],
   "source": [
    "# Capture route and stored into .txt file\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('Manhattan_trajectory_mapped_node.csv')\n",
    "\n",
    "# 打开一个新的文本文件用于写入数据\n",
    "with open('route.txt', 'w') as file:\n",
    "    # 遍历 DataFrame 中的每一行\n",
    "    for index, row in df.iterrows():\n",
    "        # 分割 node ID 序列并将每个节点 ID 转换为整数\n",
    "        node_sequence = [int(float(node_id)) for node_id in row['route_by_mappped_node'].split()]\n",
    "        node_count = len(node_sequence)\n",
    "\n",
    "        # 将节点数量和整数形式的节点序列按格式写入文件\n",
    "        file.write(f\"{node_count} {' '.join(map(str, node_sequence))}\\n\")\n",
    "\n",
    "print(\"Data has been written to route.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e0c95b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to time_counts_and_values.txt\n"
     ]
    }
   ],
   "source": [
    "# Capture time and stored into .txt file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('Manhattan_trajectory_mapped_node.csv')\n",
    "\n",
    "# 打开一个新的文本文件用于写入数据\n",
    "with open('time_counts_and_values.txt', 'w') as file:\n",
    "    # 遍历 DataFrame 中的每一行\n",
    "    for index, row in df.iterrows():\n",
    "        # 分割时间数据并将每个时间数据转换为整数\n",
    "        time_sequence = [int(float(time)) for time in row['exit_times'].split()]\n",
    "        time_count = len(time_sequence)\n",
    "\n",
    "        # 将时间数量和整数形式的时间数据按格式写入文件\n",
    "        file.write(f\"{time_count} {' '.join(map(str, time_sequence))}\\n\")\n",
    "\n",
    "print(\"Data has been written to time_counts_and_values.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6165d89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
